{
 "metadata": {
  "name": "",
  "signature": "sha256:f2f9d00978fa10a312c7cdfd64f218d84c2f9f61faae83c6750a9a09d2d1e898"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "from sklearn import cluster,datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dataset\n",
      "\n",
      "Let's generate a simple gaussian mixture to benchmark K-Means."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N=10**4\n",
      "D_gen=2\n",
      "K_gen=10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,A_true=sklearn.datasets.make_blobs(n_samples=N, n_features=D_gen, centers=K_gen, cluster_std=1.0, center_box=(-100.0, 100.0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# K-Means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "K=10\n",
      "N_inits=500\n",
      "max_iter=20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "centroids,A_clust,c,=sklearn.cluster.k_means(X, K, init='random',\n",
      "                                             precompute_distances=True, n_init=N_inits,\n",
      "                                             max_iter=max_iter, random_state=None, copy_x=True,\n",
      "                                             n_jobs=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 5.07 s per loop\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The documentation claims that the precompute_distances (True by default) will consume more memory but make the algorithm faster. For the our goal (run K-Means many times with a small number of iterations) this is not the case, as shown by the result below. The documentation does not offer insight on the influence that this parameter is having under the hood."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "centroids,A_clust,c,=sklearn.cluster.k_means(X, K, init='random', \n",
      "                                            precompute_distances=False, n_init=N_inits, \n",
      "                                            max_iter=max_iter, random_state=None, copy_x=True, \n",
      "                                            n_jobs=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.66 s per loop\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The K-Means function from the [scikit-learn](http://scikit-learn.org) already supports CPU parallelization by changing a simple parameter in the function. As expected, using multiple cores resulted in a speedup, albeit small. The parallelization is being done on the pairwise distances computation. It breaks down the pairwise matrix by the number of jobs selected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "centroids,A_clust,c,=sklearn.cluster.k_means(X, K, init='random',\n",
      "                                             precompute_distances=True, n_init=N_inits,\n",
      "                                             max_iter=max_iter, random_state=None, copy_x=True,\n",
      "                                             n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 6.63 s per loop\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "centroids,A_clust,c,=sklearn.cluster.k_means(X, K, init='random',\n",
      "                                             precompute_distances=False, n_init=N_inits,\n",
      "                                             max_iter=max_iter, random_state=None, copy_x=True,\n",
      "                                             n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 2.29 s per loop\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It should be noted that it seems that this implementation is being accelerated by compiled C code.n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This are the times from the code above before the installation of optimized MKL sklearn (from the Anaconda Accelerate addon).\n",
      "```\n",
      "1 loops, best of 3: 5.67 s per loop\n",
      "1 loops, best of 3: 4.05 s per loop\n",
      "1 loops, best of 3: 3.29 s per loop\n",
      "1 loops, best of 3: 2.57 s per loop\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# CUDA"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Following video tutorial on [youtubelink](http://www.youtube.com)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numbapro\n",
      "from numbapro import jit, cuda, int32, float32, float64\n",
      "\n",
      "#@jit(complex64(int32, float32, complex64), target=\"cpu\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numbapro.check_cuda()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "------------------------------libraries detection-------------------------------\n",
        "Finding cublas\n",
        "\tlocated at /home/chiroptera/anaconda/lib/libcublas.so.6.0.37\n",
        "\ttrying to open library...\tok"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding cusparse\n",
        "\tlocated at /home/chiroptera/anaconda/lib/libcusparse.so.6.0.37\n",
        "\ttrying to open library...\tok"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding cufft\n",
        "\tlocated at /home/chiroptera/anaconda/lib/libcufft.so.6.0.37\n",
        "\ttrying to open library...\tok"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding curand\n",
        "\tlocated at /home/chiroptera/anaconda/lib/libcurand.so.6.0.37\n",
        "\ttrying to open library...\tok"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding nvvm\n",
        "\tlocated at /home/chiroptera/anaconda/lib/libnvvm.so.2.0.0\n",
        "\ttrying to open library...\tok"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tfinding libdevice for compute_20...\tok\n",
        "\tfinding libdevice for compute_30...\tok\n",
        "\tfinding libdevice for compute_35...\tok\n",
        "-------------------------------hardware detection-------------------------------\n",
        "Found 1 CUDA devices\n",
        "id 0         GeForce GT 520M                              [SUPPORTED]\n",
        "                      compute capability: 2.1\n",
        "                           pci device id: 0\n",
        "                              pci bus id: 1\n",
        "Summary:\n",
        "\t1/1 devices are supported\n",
        "PASSED\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CPU version\n",
      "@numbapro.vectorize(['float32(float32,float32)',\n",
      "                     'float64(float64,float64)'],target='cpu')\n",
      "def cpu_sincos(x,y):\n",
      "    return math.sin(x) * math.cos(y)\n",
      "\n",
      "#GPU version\n",
      "@numbapro.vectorize(['float32(float32,float32)',\n",
      "                     'float64(float64,float64)'],target='gpu')\n",
      "def gpu_sincos(x,y):\n",
      "    return math.sin(x) * math.cos(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=10**6\n",
      "x = np.linspace(0,np.pi,n)\n",
      "y = np.linspace(0,np.pi,n)\n",
      "\n",
      "print 'Data of type ',x.dtype\n",
      "\n",
      "print 'Unoptimized\\t',\n",
      "%timeit np.sin(x) * np.cos(y)\n",
      "print 'CPU vectorize\\t',\n",
      "%timeit cpu_sincos(x,y)\n",
      "print 'GPU vectorize\\t',\n",
      "%timeit gpu_sincos(x,y)\n",
      "\n",
      "del x,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data of type  float64\n",
        "Unoptimized\t10 loops, best of 3: 76.3 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU vectorize\t10 loops, best of 3: 76.9 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GPU vectorize\t1 loops, best of 3: 17.9 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unoptimized and CPU vectorize times are similar because sin() and cos() calls dominate time. GPU is quite faster already and would get even faster in a better GPU (current GPU has 48 CUDA cores).\n",
      "\n",
      "All the data has to go from the RAM to the GPU memory, band back again. The work is distributed across all threads on the GPU and scheduling and memory management are taken cared of."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Another example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numbapro.vectorize(['float32(float32,float32,float32,float32)'])\n",
      "def cpu_powers(p,q,r,s):\n",
      "    return math.sqrt(p**2 + q**3 + r**4 + s**5)\n",
      "\n",
      "@numbapro.vectorize(['float32(float32,float32,float32,float32)'],target='gpu')\n",
      "def gpu_powers(p,q,r,s):\n",
      "    return math.sqrt(p**2 + q**3 + r**4 + s**5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When target is not specified, it defaults to 'cpu'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Benchmarking\n",
      "#Generate data\n",
      "n=5e6\n",
      "p = np.random.random(n).astype(np.float32)\n",
      "q = np.random.random(n).astype(np.float32)\n",
      "r = np.random.random(n).astype(np.float32)\n",
      "s = np.random.random(n).astype(np.float32)\n",
      "\n",
      "print 'Unoptimized\\t',\n",
      "%timeit np.sqrt(p**2 + q**3 + r**4 + s**5)\n",
      "print 'CPU vectorize\\t',\n",
      "%timeit cpu_powers(p,q,r,s)\n",
      "print 'GPU vectorize\\t',\n",
      "%timeit gpu_powers(p,q,r,s)\n",
      "\n",
      "del p,q,r,s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unoptimized\t1 loops, best of 3: 2.99 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU vectorize\t1 loops, best of 3: 2.25 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GPU vectorize\t10 loops, best of 3: 80 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Anaconda Accelerate includes the MKL optimization to several libraries. I still have to check if the numpy routines are not faster than the normal ones.\n",
      "\n",
      "The speedup of GPU over CPU is of $$2.1 s / 69.4 ms = 30.26$$ \n",
      "\n",
      "We've now seen that @vectorize accelerates functions, specially on GPU, but it only works on scalar functions. Even though more complex operations like matrix multiplication can be decomposed in several scalar operations over its elements, it would be more convenient to operate on arrays directly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## GUVectorize and  General Universal Functions (ufunc)\n",
      "\n",
      "Now the function can't return anything and we should pass as a parameter where we want our result to be stored. Furthermore, it's now clear that the types are arrays and we have an extra descriptive string for the shape signature."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numbapro.guvectorize(['void(float32[:,:], float32[:,:], float32[:,:])'],'(m,n),(n,p)->(m,p)',target='gpu')\n",
      "def batch_matrix_mult(a,b,c):\n",
      "    for i in range(c.shape[0]):\n",
      "        for j in range(c.shape[1]):\n",
      "            tmp=0\n",
      "            for n in range(a.shape[1]):\n",
      "                tmp += a[i,n] * b[n,j]\n",
      "            c[i,j]=tmp\n",
      "#batch_matrix_mult.max_blocksize = 32  # limits to 32 threads per block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the code from the video. It seems to be a simple matrix multiplication though. In the video they say that it's a batch multuplication..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=4e7\n",
      "dim=2\n",
      "\n",
      "print 'Memory for both matrices:\\t',((2*n*dim*dim*4)/1024),' KBytes'\n",
      "\n",
      "a=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "b=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "\n",
      "\n",
      "print 'Exception when too much resources of GPU are used:'\n",
      "try:\n",
      "    batch_matrix_mult(a,b)\n",
      "except Exception as exception:\n",
      "    print exception\n",
      "\n",
      "batch_matrix_mult.max_blocksize = 64  # limits to 32 threads per block    \n",
      "\n",
      "import numpy.core.umath_tests as ut\n",
      "\n",
      "print 'Unoptimized\\t',\n",
      "#c = np.dot(a,b)\n",
      "%timeit c = ut.matrix_multiply(a,b)\n",
      "\n",
      "print 'GUVectorize GPU\\t',\n",
      "%timeit c2 = batch_matrix_mult(a,b)\n",
      "\n",
      "del n,dim,a,b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Memory for both matrices:\t1250000.0  KBytes\n",
        "Exception when too much resources of GPU are used:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Call to cuMemAlloc results in CUDA_ERROR_OUT_OF_MEMORY"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Unoptimized\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.64 s per loop\n",
        "GUVectorize GPU\t"
       ]
      },
      {
       "ename": "CudaAPIError",
       "evalue": "Call to cuMemAlloc results in CUDA_ERROR_OUT_OF_MEMORY",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-42-8d7762ca3a78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'GUVectorize GPU\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit c2 = batch_matrix_mult(a,b)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/timeit.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numbapro/cudavec/dispatch.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kws)\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/devices.pyc\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[1;34m(*args, **kws)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/api.pyc\u001b[0m in \u001b[0;36mdevice_array\u001b[1;34m(shape, dtype, strides, order, stream)\u001b[0m\n\u001b[0;32m     70\u001b[0m                                                          order)\n\u001b[0;32m     71\u001b[0m     return devicearray.DeviceNDArray(shape=shape, strides=strides, dtype=dtype,\n\u001b[1;32m---> 72\u001b[1;33m                                      stream=stream)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/devicearray.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shape, strides, dtype, stream, writeback, gpu_head, gpu_data)\u001b[0m\n\u001b[0;32m     94\u001b[0m                                                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                                                                 self.dtype.itemsize)\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mgpu_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemalloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_memory_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36mmemalloc\u001b[1;34m(self, bytesize)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrashing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrvapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcu_device_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuMemAlloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytesize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[0m_memory_finalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_mem_finalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuMemFree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         mem = MemoryPointer(weakref.proxy(self), ptr, bytesize,\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0merrname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mERROR_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UNKNOWN_CUDA_ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Call to %s results in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mCudaAPIError\u001b[0m: Call to cuMemAlloc results in CUDA_ERROR_OUT_OF_MEMORY"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del n,dim,a,b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the [documentation](http://docs.continuum.io/numbapro/CUDAufunc.html):\n",
      "> There are times when the gufunc kernel uses too many of a GPU\u2019s resources, which can cause the kernel launch to fail. The user can explicitly control the maximum size of the thread block by setting the max_blocksize attribute on the compiled gufunc object.\n",
      "\n",
      "To control the size of the thread block we use (e.g. for 32 threds per block):\n",
      "```python\n",
      "very_complex_kernel.max_blocksize = 32\n",
      "```\n",
      "\n",
      "The speedup was of \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Manual memory management\n",
      "\n",
      "The performance increases when the memory is manually managed. We'll run the same test as before, but now we'll copy the arrays to the GPU's memory and also allocate memory for the result. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=20e6\n",
      "dim=2\n",
      "\n",
      "print 'Memory for both matrices:\\t',((2*n*dim*dim*4)/1024),' KBytes'\n",
      "\n",
      "a=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "b=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "\n",
      "dc = numbapro.cuda.device_array_like(a)\n",
      "da = numbapro.cuda.to_device(a)\n",
      "db = numbapro.cuda.to_device(b)\n",
      "\n",
      "def check_pure_compute_time(da,db,dc):\n",
      "    batch_matrix_mult(da,db,out=dc)\n",
      "    numbapro.cuda.synchronize()\n",
      "    \n",
      "import numpy.core.umath_tests as ut\n",
      "\n",
      "print 'Unoptimized\\t',\n",
      "#c = np.dot(a,b)\n",
      "%timeit c = ut.matrix_multiply(a,b)\n",
      "\n",
      "print 'Memory management'\n",
      "batch_matrix_mult.max_blocksize = 64  # limits to 32 threads per block    \n",
      "\n",
      "print 'Automatic:\\t\\t',\n",
      "%timeit c=batch_matrix_mult(a,b)\n",
      "print 'Manual:\\t\\t\\t',\n",
      "%timeit check_pure_compute_time(da,db,dc)\n",
      "\n",
      "del n,dim,a,b,da,db,dc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Memory for both matrices:\t625000.0  KBytes\n"
       ]
      },
      {
       "ename": "CudaAPIError",
       "evalue": "Call to cuMemAlloc results in CUDA_ERROR_OUT_OF_MEMORY",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-18-38abfe770499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumbapro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumbapro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumbapro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_pure_compute_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/devices.pyc\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[1;34m(*args, **kws)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/api.pyc\u001b[0m in \u001b[0;36mto_device\u001b[1;34m(ary, stream, copy, to)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mdevarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevicearray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mdevarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/devicearray.pyc\u001b[0m in \u001b[0;36mfrom_array_like\u001b[1;34m(ary, stream, gpu_head, gpu_data)\u001b[0m\n\u001b[0;32m    336\u001b[0m     return DeviceNDArray(ary.shape, ary.strides, ary.dtype,\n\u001b[0;32m    337\u001b[0m                          \u001b[0mwriteback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpu_head\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgpu_head\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                          gpu_data=gpu_data)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/devicearray.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shape, strides, dtype, stream, writeback, gpu_head, gpu_data)\u001b[0m\n\u001b[0;32m     94\u001b[0m                                                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                                                                 self.dtype.itemsize)\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mgpu_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemalloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_memory_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36mmemalloc\u001b[1;34m(self, bytesize)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrashing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrvapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcu_device_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuMemAlloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytesize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[0m_memory_finalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_mem_finalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuMemFree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         mem = MemoryPointer(weakref.proxy(self), ptr, bytesize,\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0merrname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mERROR_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UNKNOWN_CUDA_ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Call to %s results in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mCudaAPIError\u001b[0m: Call to cuMemAlloc results in CUDA_ERROR_OUT_OF_MEMORY"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## CUDA Execution Model\n",
      "\n",
      "Kernel function\n",
      "- are only visible o the host CPU\n",
      "- cannot return any value (use output argument)\n",
      "- associates to a grid\n",
      "\n",
      "A **grid** is a group of blocks (that can be 1D,2D or 3D) and each **block** is a group of threads (which can also be 1D, 2D or 3D). Every thread will execute the same kernel function.\n",
      "\n",
      "When we're using @jit, we're writing functions on the CUDA execution model. However, we wrote functions that executed on GPU before with a return type (which can't happen here). That is because before we were using the @vectorize and not working under the CUDA execution model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Matrix multiplication test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# DEBUG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numbapro.guvectorize(['void(float32[:,:], float32[:,:], float32[:,:])'],'(m,n),(n,p)->(m,p)',target='gpu')\n",
      "def matrix_mult(a,b,c):\n",
      "    for i in range(c.shape[0]):\n",
      "        for j in range(c.shape[1]):\n",
      "            tmp=0\n",
      "            for n in range(a.shape[1]):\n",
      "                tmp += a[i,n] * b[n,j]\n",
      "            c[i,j]=tmp\n",
      "#batch_matrix_mult.max_blocksize = 32  # limits to 32 threads per block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=4e6\n",
      "dim=2\n",
      "\n",
      "print 'Memory for both matrices:\\t',((2*n*dim*dim*4)/1024),' KBytes'\n",
      "\n",
      "a=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "b=np.random.random(n*dim*dim).astype(np.float32).reshape(n,dim,dim)\n",
      "\n",
      "dc = numbapro.cuda.device_array_like(a)\n",
      "da = numbapro.cuda.to_device(a)\n",
      "db = numbapro.cuda.to_device(b)\n",
      "\n",
      "def check_pure_compute_time(da,db,dc):\n",
      "    batch_matrix_mult(da,db,out=dc)\n",
      "    numbapro.cuda.synchronize()\n",
      "    \n",
      "del a,b,da,db,dc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Memory for both matrices:\t125000.0  KBytes\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "tpb=10e6 / (10*10)\n",
      "print tpb\n",
      "print np.sqrt(tpb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000.0\n",
        "316.227766017\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numbapro import *\n",
      "from timeit import default_timer as timer\n",
      "\n",
      "m=1000\n",
      "n=1000\n",
      "A = np.array(np.random.random((n,m)), dtype=np.float32)\n",
      "C = np.empty([n,n])\n",
      "B = np.array(np.random.random((m,n)), dtype=np.float32)\n",
      "\n",
      "%timeit X=np.dot(A,B)\n",
      "\n",
      "@cuda.jit(void(float32[:,:],float32[:,:],float32[:,:]))\n",
      "def cu_square_matrix_mul(A, B, C):\n",
      "\n",
      "    tx = cuda.threadIdx.x\n",
      "    ty = cuda.threadIdx.y\n",
      "    \n",
      "    bx = cuda.blockIdx.x\n",
      "    by = cuda.blockIdx.y\n",
      "    \n",
      "    bw = cuda.blockDim.x\n",
      "    bh = cuda.blockDim.y\n",
      "    \n",
      "    x = tx + bx * bw\n",
      "    y = ty + by * bh\n",
      "    \n",
      "    n = C.shape[0]\n",
      "\n",
      "    if x >= n or y >= n:\n",
      "        return\n",
      "\n",
      "    cs = 0\n",
      "    for i in range(n):\n",
      "        cs += A[y,i]*B[i,x]\n",
      "    C[y,x]= cs\n",
      "\n",
      "    cuda.syncthreads()\n",
      "    \n",
      "def check_pure_compute_time(dA,dB,dC):\n",
      "    stream = cuda.stream()\n",
      "    blockdim = 10,10\n",
      "    griddim = 10,10\n",
      "    cu_square_matrix_mul[griddim,blockdim,stream](dA, dB,dC)\n",
      "    dC.to_host()\n",
      "    stream.synchronize()\n",
      "\n",
      "\n",
      "\n",
      "stream = cuda.stream()\n",
      "dA = cuda.to_device(A, stream)\n",
      "dC = cuda.to_device(C, stream)\n",
      "B = np.array(np.random.random((m,n)), dtype=np.float32)\n",
      "dB = cuda.to_device(B, stream)\n",
      "\n",
      "check_pure_compute_time(dA,dB,dC)       \n",
      "\"\"\"\n",
      "print\n",
      "print(\"Numpy took    %f seconds\" % numpy_time)\n",
      "print(\"CUDA JIT took %f seconds, %.5fx speedup\" % (cuda_time, numpy_time / cuda_time))\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 46 ms per loop\n"
       ]
      },
      {
       "ename": "CudaAPIError",
       "evalue": "Call to cuLaunchKernel results in CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-46-99de67136a24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mdB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mcheck_pure_compute_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \"\"\"\n\u001b[0;32m     53\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-46-99de67136a24>\u001b[0m in \u001b[0;36mcheck_pure_compute_time\u001b[1;34m(dA, dB, dC)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mblockdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mgriddim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mcu_square_matrix_mul\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mdC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/compiler.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                           \u001b[0mblockdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                           \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                           sharedmem=self.sharedmem)\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/compiler.pyc\u001b[0m in \u001b[0;36m_kernel_call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    345\u001b[0m                                    sharedmem=sharedmem)\n\u001b[0;32m    346\u001b[0m         \u001b[1;31m# invoke kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0mcu_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         launch_kernel(self.handle, self.griddim, self.blockdim,\n\u001b[1;32m-> 1045\u001b[1;33m                       self.sharedmem, streamhandle, args)\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[1;34m(cufunc_handle, griddim, blockdim, sharedmem, hstream, args)\u001b[0m\n\u001b[0;32m   1087\u001b[0m                           \u001b[0mhstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m                           \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                           None)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0merrname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mERROR_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UNKNOWN_CUDA_ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Call to %s results in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mCudaAPIError\u001b[0m: Call to cuLaunchKernel results in CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_gpu = numba.cuda.get_current_device()\n",
      "print \"Running on GPU:\", my_gpu.name\n",
      "cores_per_capability = {1: 8,2: 32,3: 192,}\n",
      "cc = my_gpu.compute_capability\n",
      "print \"Compute capability: \", \"%d.%d\" % cc, \"(Numba requires >= 2.0)\"\n",
      "majorcc = cc[0]\n",
      "print \"Number of streaming multiprocessor:\", my_gpu.MULTIPROCESSOR_COUNT\n",
      "cores_per_multiprocessor = cores_per_capability[majorcc]\n",
      "print \"Number of cores per mutliprocessor:\", cores_per_multiprocessor\n",
      "total_cores = cores_per_multiprocessor * my_gpu.MULTIPROCESSOR_COUNT\n",
      "print \"Number of cores on GPU:\", total_cores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running on GPU: GeForce GT 520M\n",
        "Compute capability:  2.1 (Numba requires >= 2.0)\n",
        "Number of streaming multiprocessor: 1\n",
        "Number of cores per mutliprocessor: 32\n",
        "Number of cores on GPU: 32\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Distance calculation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dist(a,b,c):\n",
      "    N,K = c.shape\n",
      "    dim = a.shape[1]\n",
      "   \n",
      "    for n in range(N):\n",
      "        for k in range(K):\n",
      "            dist=0\n",
      "            for d in range(dim):\n",
      "                diff = a[n,d]-b[k,d]\n",
      "                dist += diff ** 2\n",
      "            c[n,k]=dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numbapro.cuda.jit(\"void(float32[:,:],float32[:,:],float32[:,:])\")\n",
      "def cu_dist(a,b,c):\n",
      "    \n",
      "    # thread ID inside block\n",
      "    tx = cuda.threadIdx.x\n",
      "    ty = cuda.threadIdx.y\n",
      "    \n",
      "    # block ID\n",
      "    bx = cuda.blockIdx.x\n",
      "    by = cuda.blockIdx.y\n",
      "    \n",
      "    # block dimensions\n",
      "    bw = cuda.blockDim.x\n",
      "    bh = cuda.blockDim.y\n",
      "    \n",
      "    # compute thread's x and y index (i.e. datapoint and cluster)\n",
      "    k = tx + bx * bw # column for each cluster\n",
      "    n = ty + by * bh # row for each datapoint\n",
      "    \n",
      "    ch, cw = c.shape # c width and height\n",
      "\n",
      "    if n >= ch or k >= cw:\n",
      "        return\n",
      "\n",
      "    dist = 0.0\n",
      "    for d in range(a.shape[1]):\n",
      "        diff = a[n,d]-b[k,d]\n",
      "        dist += diff ** 2\n",
      "    c[n,k]= dist\n",
      "\n",
      "    cuda.syncthreads()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_pure_compute_time(a,b,c,blockDim,gridDim):\n",
      "    dA = cuda.to_device(a)\n",
      "    dB = cuda.to_device(b)\n",
      "    dC = cuda.to_device(c)\n",
      "    #dC = numbapro.cuda.device_array(c)\n",
      "    stream = cuda.stream()\n",
      "    cu_dist[gridDim,blockDim,stream](dA,dB,dC)\n",
      "    dC.to_host()\n",
      "    stream.synchronize() #block untill stream is done\n",
      "    return dC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numbapro.cuda.device_array((20,20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7fb63ad3f250>"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data.dtype,clusters.dtype,dists.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "float32 float32 float32\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%debug\n",
      "##generate data\n",
      "n = 1e6\n",
      "d = 2\n",
      "k = 20\n",
      "\n",
      "total_bytes = (n * d + k * d + n * k) * 4\n",
      "print 'Memory used by arrays:\\t',total_bytes/1024,'\\tKBytes'\n",
      "print '\\t\\t\\t',total_bytes/(1024*1024),'\\tMBytes'\n",
      "\n",
      "data = np.random.random((n,d)).astype(np.float32)\n",
      "clusters = np.random.random((k,d)).astype(np.float32)\n",
      "dists = np.empty((n,d)).astype(np.float32)\n",
      "distsDim = np.int(n),np.int(k)\n",
      "\n",
      "blockDim = 8,6 # I have 48 CUDA cores in GT520M\n",
      "\n",
      "numBlocks = np.ceil((n * k) / 48)\n",
      "gridSquareSide = np.ceil(np.sqrt(numBlocks))\n",
      "gridDim = gridSquareSide,gridSquareSide\n",
      "\n",
      "print 'Excesss threads:\\t',\n",
      "print  np.prod(gridDim)*np.prod(blockDim) - (n * k)\n",
      "\n",
      "#%timeit -r 1 dist(data,clusters,dists)\n",
      "#%timeit -r 1 \n",
      "dists = check_pure_compute_time(data,clusters,dists,blockDim,gridDim)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Memory used by arrays:\t85937.65625 \tKBytes\n",
        "\t\t\t83.9234924316 \tMBytes\n",
        "Excesss threads:\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31168.0\n"
       ]
      },
      {
       "ename": "ArgumentError",
       "evalue": "argument 2: <type 'exceptions.TypeError'>: wrong type",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-199-389a894bee55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#%timeit -r 1 dist(data,clusters,dists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#%timeit -r 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pure_compute_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdists\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblockDim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgridDim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-183-12acc2ac0aaa>\u001b[0m in \u001b[0;36mcheck_pure_compute_time\u001b[1;34m(a, b, c, blockDim, gridDim)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#dC = numbapro.cuda.device_array(c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcu_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgridDim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblockDim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mdC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#block untill stream is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/compiler.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                           \u001b[0mblockdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                           \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                           sharedmem=self.sharedmem)\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/compiler.pyc\u001b[0m in \u001b[0;36m_kernel_call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    345\u001b[0m                                    sharedmem=sharedmem)\n\u001b[0;32m    346\u001b[0m         \u001b[1;31m# invoke kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0mcu_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         launch_kernel(self.handle, self.griddim, self.blockdim,\n\u001b[1;32m-> 1045\u001b[1;33m                       self.sharedmem, streamhandle, args)\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[1;34m(cufunc_handle, griddim, blockdim, sharedmem, hstream, args)\u001b[0m\n\u001b[0;32m   1087\u001b[0m                           \u001b[0mhstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m                           \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                           None)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chiroptera/anaconda/lib/python2.7/site-packages/numba/cuda/cudadrv/driver.pyc\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mArgumentError\u001b[0m: argument 2: <type 'exceptions.TypeError'>: wrong type"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del data,clusters,dists"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    }
   ],
   "metadata": {}
  }
 ]
}