{
 "metadata": {
  "name": "",
  "signature": "sha256:cc999ad108288d1ce935a6d8333cd92c9ad272d26df2a30f70989cae5998e2a4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numbapro\n",
      "from numbapro import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load https://raw.githubusercontent.com/Chiroptera/QCThesis/master/CUDA/K_Means.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Fri Mar 27 08:53:20 2015\n",
      "\n",
      "@author: Diogo Silva\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "import numbapro\n",
      "from numbapro import *\n",
      "\n",
      "class K_Means:       \n",
      "       \n",
      "    \n",
      "    def __init__(self,N=None,D=None,K=None):\n",
      "        self.N = N\n",
      "        self.D = D\n",
      "        self.K = K\n",
      "        \n",
      "        self._cudaDataRef = None \n",
      "        \n",
      "    def fit(self,data,K,iters=3,cuda=False):\n",
      "        \n",
      "        N,D = data.shape\n",
      "            \n",
      "        self.N = N\n",
      "        self.D = D\n",
      "        self.K = K\n",
      "        \n",
      "        centroids = self._init_centroids(data)\n",
      "        \n",
      "        if iters == 0:\n",
      "            return\n",
      "        \n",
      "        for i in xrange(iters):\n",
      "            dist_mat = self._calc_dists(data,centroids,cuda=cuda)\n",
      "            assign,grouped_data = self._assign_data(data,dist_mat)\n",
      "            centroids =  self._np_recompute_centroids(grouped_data)\n",
      "            self.centroids = centroids\n",
      "\n",
      "    def _init_centroids(self,data):\n",
      "        \n",
      "        centroids = np.empty((self.K,self.D),dtype=data.dtype)\n",
      "        random_init = np.random.randint(0,self.N,self.K)\n",
      "        self.init_seed = random_init\n",
      "        \n",
      "        for k in xrange(self.K):\n",
      "            centroids[k] = data[random_init[k]]\n",
      "        \n",
      "        self.centroids = centroids\n",
      "        \n",
      "        return centroids\n",
      "\n",
      "    def _calc_dists(self,data,centroids,cuda=False):\n",
      "        if cuda:\n",
      "            dist_mat = self._cu_calc_dists(data,centroids,gridDim=None,\n",
      "                                           blockDim=None,memManage='manual')\n",
      "        else:\n",
      "            dist_mat = self._np_calc_dists(data,centroids)\n",
      "            \n",
      "        return dist_mat\n",
      "            \n",
      "    def _py_calc_dists(data,centroids):\n",
      "        N,D = data.shape\n",
      "        K,cD = centroids.shape\n",
      "\n",
      "        for n in range(N):\n",
      "            for k in range(K):\n",
      "                dist=0\n",
      "                for d in range(dim):\n",
      "                    diff = a[n,d]-b[k,d]\n",
      "                    dist += diff ** 2\n",
      "                c[n,k]=dist\n",
      "            \n",
      "    def _np_calc_dists(self,data,centroids):\n",
      "        \"\"\"\n",
      "        NumPy implementation - much faster than vanilla Python\n",
      "        \"\"\"\n",
      "        N,D = data.shape\n",
      "        K,cD = centroids.shape\n",
      "\n",
      "        dist_mat = np.empty((N,K),dtype=data.dtype)    \n",
      "        \n",
      "        for k in xrange(K):\n",
      "            dist = data - centroids[k]\n",
      "            dist = dist ** 2\n",
      "            dist_mat[:,k] = dist.sum(axis=1)\n",
      "            \n",
      "        return dist_mat\n",
      "    \n",
      "    def _cu_calc_dists(self,data,centroids,gridDim=None,blockDim=None,\n",
      "                       memManage='manual',keepDataRef=True):\n",
      "        \"\"\"\n",
      "        TODO:\n",
      "            - deal with gigantic data / distance matrix\n",
      "            - deal with heavely assymetric distance matrix\n",
      "                - if the number of blocks on any given dimension of \n",
      "                the grid > 2**16, divide that dimension by another dimension\n",
      "                - don't forget to change the index computation in the kernel\n",
      "        \"\"\"\n",
      "        \n",
      "        \n",
      "        N,D = data.shape\n",
      "        K,cD = centroids.shape\n",
      "        \n",
      "        if memManage not in ('manual','auto'):\n",
      "            raise Exception(\"Invalid value for \\'memManage\\'.\")\n",
      "\n",
      "            \n",
      "        if gridDim is None or blockDim is None:\n",
      "            #dists shape\n",
      "            \n",
      "\n",
      "            MAX_THREADS_BLOCK = 28 * 20 # GT520M has 48 CUDA cores\n",
      "            MAX_GRID_XYZ_DIM = 65535\n",
      "\n",
      "            if K <= 28:\n",
      "                blockWidth = K\n",
      "                blockHeight = np.floor(MAX_THREADS_BLOCK / blockWidth)\n",
      "                blockHeight = np.int(blockHeight)\n",
      "            else:\n",
      "                blockWidth = 20\n",
      "                blockHeight = 28\n",
      "\n",
      "            # grid width/height is the number of blocks necessary to fill\n",
      "            # the columns/rows of the matrix\n",
      "            gridWidth = np.ceil(np.float(K) / blockWidth)\n",
      "            gridHeight = np.ceil(np.float(N) / blockHeight)\n",
      "\n",
      "    \n",
      "            blockDim = blockWidth, blockHeight\n",
      "            gridDim = np.int(gridWidth), np.int(gridHeight)\n",
      "            \n",
      "        distShape =  N,K\n",
      "        dist_mat = np.empty(distShape,dtype=data.dtype)\n",
      "        \n",
      "        if memManage == 'manual':\n",
      "            \n",
      "            if keepDataRef:\n",
      "                if self._cudaDataRef is None:\n",
      "                    dData = cuda.to_device(data)\n",
      "                    self._cudaDataRef = dData\n",
      "                else:\n",
      "                    dData = self._cudaDataRef\n",
      "            else:\n",
      "                dData = cuda.to_device(data)\n",
      "                \n",
      "            dCentroids = cuda.to_device(centroids)\n",
      "            dDists = numbapro.cuda.device_array_like(dist_mat)\n",
      "            \n",
      "            self._cu_dist_kernel[gridDim,blockDim](dData,dCentroids,dDists)        \n",
      "        \n",
      "            dDists.copy_to_host(ary=dist_mat)\n",
      "            numbapro.cuda.synchronize()\n",
      "\n",
      "        elif memManage == 'auto':\n",
      "            self._cu_dist_kernel[gridDim,blockDim](data,centroids,dist_mat) \n",
      "        \n",
      "        return dist_mat\n",
      "        \n",
      "    \n",
      "    @numbapro.cuda.jit(\"void(float32[:,:], float32[:,:], float32[:,:])\")\n",
      "    def _cu_dist_kernel(a,b,c):\n",
      "        k,n = numbapro.cuda.grid(2)\n",
      "\n",
      "        ch, cw = c.shape # c width and height\n",
      "\n",
      "        if n >= ch or k >= cw:\n",
      "            return\n",
      "\n",
      "        dist = 0.0\n",
      "        for d in range(a.shape[1]):\n",
      "            diff = a[n,d]-b[k,d]\n",
      "            dist += diff ** 2\n",
      "        c[n,k]= dist\n",
      "    \n",
      "        \n",
      "    def _assign_data(self,data,dist_mat):\n",
      "        \n",
      "        N,K = dist_mat.shape\n",
      "        \n",
      "        assign = np.argmin(dist_mat,axis=1)\n",
      "        \n",
      "        grouped_data=[[] for i in xrange(K)]\n",
      "        \n",
      "        \n",
      "        for n in xrange(N):\n",
      "            # add datum i to its assigned cluster assign[i]\n",
      "            grouped_data[assign[n]].append(data[n])\n",
      "        \n",
      "        for k in xrange(K):\n",
      "            grouped_data[k] = np.array(grouped_data[k])\n",
      "        \n",
      "        return assign,grouped_data\n",
      "    \n",
      "    def _np_recompute_centroids(self,grouped_data):\n",
      "        \n",
      "        # change to get dimension from class or search a non-empty cluster\n",
      "        #dim = grouped_data[0][0].shape[1]\n",
      "        dim = self.D\n",
      "        K = len(grouped_data)\n",
      "        \n",
      "        centroids = np.empty((K,dim))\n",
      "        for k in xrange(K):\n",
      "            centroids[k] = np.mean(grouped_data[k],axis=0)\n",
      "        \n",
      "        return centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##generate data\n",
      "n = 1e6\n",
      "d = 2\n",
      "k = 20\n",
      "\n",
      "total_bytes = (n * d + k * d + n * k) * 4\n",
      "print 'Memory used by arrays:\\t',total_bytes/1024,'\\tKBytes'\n",
      "print '\\t\\t\\t',total_bytes/(1024*1024),'\\tMBytes'\n",
      "\n",
      "print 'Memory used by data:  \\t',n * d * 4 / 1024,'\\t','KBytes'\n",
      "\n",
      "data = np.random.random((n,d)).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Memory used by arrays:\t85937.65625 \tKBytes\n",
        "\t\t\t83.9234924316 \tMBytes\n",
        "Memory used by data:  \t7812.5 \tKBytes\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from timeit import default_timer as timer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "times=dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = timer()\n",
      "grouperCUDA = K_Means()\n",
      "grouperCUDA.fit(data,k,iters=3,cuda=True)\n",
      "times['cuda'] = timer() - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%debug\n",
      "start = timer()\n",
      "grouperNP = K_Means()\n",
      "grouperNP.fit(data,k,cuda=False)\n",
      "times['numpy'] = timer() - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Times'\n",
      "print 'CUDA ','\\t',times['cuda']\n",
      "print 'NumPy','\\t',times['numpy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Times\n",
        "CUDA  \t29.3555300236\n",
        "NumPy \t32.5373690128\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cProfile\n",
      "#from line_profiler import LineProfiler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named line_profiler",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-a0b61c615a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mline_profiler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLineProfiler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mImportError\u001b[0m: No module named line_profiler"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#profile = LineProfiler(grouperCUDA.fit(data,k,iters=3,cuda=True))\n",
      "#profile.print_stats()\n",
      "#cProfile.run(\"grouperCUDA.fit(data,k,iters=3,cuda=True)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#profile = LineProfiler(grouperCUDA.fit(data,k,iters=3,cuda=True))\n",
      "#profile.print_stats()\n",
      "#cProfile.run(\"grouperCUDA.fit(data,k,iters=3,cuda=False)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Speedup:','\\t\\t', 1.367/0.319\n",
      "print 'Centroids portion','\\t',25.2/31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Speedup: \t\t4.28526645768\n",
        "Centroids portion \t0.812903225806\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "Profiling both runs (CUDA and NumPy) we see that we have a speedup, but it's very small. In fact, the speedup of the optimized portions of the code is around 4 but the rest is so slow that it makes very little impact. What's taking the most time is the centroid recalculation, taking around 80% of the total time. This is the obvious next step for optimization."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}